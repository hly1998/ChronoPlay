# -*- coding: utf-8 -*-
"""
ç‹¬ç«‹ç”Ÿæˆè¿è¡Œå™¨
åŸºäºæ£€ç´¢ç»“æœæ–‡ä»¶ç”Ÿæˆç­”æ¡ˆ
"""

import argparse
import json
from pathlib import Path

from components import GenerationConfig, GenerationPipeline


def main():
    """ç”Ÿæˆä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç‹¬ç«‹ç”Ÿæˆè¿è¡Œå™¨')

    # åŸºç¡€å‚æ•°
    parser.add_argument('--retrieval_file', required=True, help='æ£€ç´¢ç»“æœæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output_file', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')

    # ç”Ÿæˆé…ç½®
    parser.add_argument('--api_key', default='{your-api-key}')
    parser.add_argument('--base_url', default='{your-base-url}')
    parser.add_argument('--llm_model', default='gpt-4o', help='ç”Ÿæˆæ¨¡å‹')
    parser.add_argument('--temperature', type=float, default=0.1)
    parser.add_argument('--concurrent_requests', type=int, default=3, help='å¹¶å‘æ•°')

    args = parser.parse_args()

    # æ£€æŸ¥æ£€ç´¢ç»“æœæ–‡ä»¶
    retrieval_file = Path(args.retrieval_file)
    if not retrieval_file.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {retrieval_file}")
        return

    # åŠ è½½æ£€ç´¢ç»“æœ
    retrieval_results = []
    with open(retrieval_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                retrieval_results.append(json.loads(line.strip()))

    if not retrieval_results:
        print("âŒ æ£€ç´¢ç»“æœæ–‡ä»¶ä¸ºç©º")
        return

    print(f"ğŸ“Š åŠ è½½ {len(retrieval_results)} ä¸ªæ£€ç´¢ç»“æœ")
    print(f"ğŸ¤– æ¨¡å‹: {args.llm_model}, æ¸©åº¦: {args.temperature}, å¹¶å‘: {args.concurrent_requests}")

    # åˆ›å»ºç”Ÿæˆé…ç½®
    config = GenerationConfig(
        api_key=args.api_key,
        base_url=args.base_url,
        llm_model=args.llm_model,
        temperature=args.temperature,
        concurrent_requests=args.concurrent_requests,
        verbose=False
    )

    # åˆå§‹åŒ–ç”Ÿæˆpipeline
    pipeline = GenerationPipeline(config)

    # ç¡®å®šè¾“å‡ºæ–‡ä»¶
    if args.output_file:
        output_file = Path(args.output_file)
    else:
        # è‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶å
        model_name = args.llm_model.replace('-', '_').replace('/', '_')
        filename = f"generation_{retrieval_file.stem}_{model_name}.jsonl"

        output_dir = Path(config.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        output_file = output_dir / filename

    print(f"ğŸ’¾ è¾“å‡º: {output_file}")

    # æ‰§è¡Œç”Ÿæˆ
    results = pipeline.batch_generate(retrieval_results, str(output_file))

    # ç»Ÿè®¡
    success_count = len([r for r in results if 'error' not in r])
    error_count = len(results) - success_count
    print(f"âœ… å®Œæˆ: {success_count} æˆåŠŸ, {error_count} å¤±è´¥")


if __name__ == '__main__':
    main()
