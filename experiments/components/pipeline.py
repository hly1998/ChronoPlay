# -*- coding: utf-8 -*-
"""
RAG Pipelineä¸»ç»„ä»¶
"""

import json
import time
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

from llama_index.core import Document

from .config import RAGConfig
from .retriever import VectorRetriever
from .generator import TextGenerator


class RAGPipeline:
    """ç®€åŒ–çš„RAG Pipeline"""

    def __init__(self, config: RAGConfig):
        self.config = config
        self.retriever = VectorRetriever(config)
        self.generator = TextGenerator(config)
        self.documents = []

        if config.verbose:
            print("ğŸš€ åˆå§‹åŒ–RAG Pipeline")
            print(f"   æ¸¸æˆ: {config.game_name}")
            if config.target_segment_id:
                print(f"   ç›®æ ‡åˆ†æ®µ: {config.target_segment_id}")
            print(f"   åŒ…å«æ—¶é—´æ— å…³æ•°æ®: {'æ˜¯' if config.include_timeless else 'å¦'}")

    def load_documents(self) -> bool:
        """åŠ è½½æ–‡æ¡£"""
        if self.config.verbose:
            print("ğŸ“š åŠ è½½è¯­æ–™åº“...")

        corpus_dir = Path(self.config.corpus_dir) / self.config.game_name / "corpus"
        if not corpus_dir.exists():
            if self.config.verbose:
                print(f"âŒ è¯­æ–™åº“ç›®å½•ä¸å­˜åœ¨: {corpus_dir}")
            return False

        # ç¡®å®šè¦åŠ è½½çš„åˆ†æ®µç›®å½•
        segment_dirs = self._get_segment_dirs(corpus_dir)

        # åŠ è½½æ–‡æ¡£
        self.documents = []
        for segment_dir in segment_dirs:
            self._load_segment_documents(segment_dir)

        if self.config.verbose:
            self._print_document_stats()

        return len(self.documents) > 0

    def _get_segment_dirs(self, corpus_dir: Path) -> List[Path]:
        """è·å–è¦åŠ è½½çš„åˆ†æ®µç›®å½•"""
        if self.config.target_segment_id:
            # åŠ è½½æŒ‡å®šåˆ†æ®µ
            dirs = [corpus_dir / f"segment_{self.config.target_segment_id}"]
            if self.config.include_timeless:
                timeless_dir = corpus_dir / "segment_timeless"
                if timeless_dir.exists():
                    dirs.append(timeless_dir)
        else:
            # åŠ è½½æ‰€æœ‰åˆ†æ®µ
            dirs = [d for d in corpus_dir.iterdir() if d.is_dir() and d.name.startswith('segment_')]
            if self.config.include_timeless:
                timeless_dir = corpus_dir / "segment_timeless"
                if timeless_dir.exists() and timeless_dir not in dirs:
                    dirs.append(timeless_dir)
        return dirs

    def _load_segment_documents(self, segment_dir: Path):
        """åŠ è½½å•ä¸ªåˆ†æ®µçš„æ–‡æ¡£"""
        corpus_file = segment_dir / "corpus.jsonl"
        if not corpus_file.exists():
            return

        if self.config.verbose:
            print(f"ğŸ“„ åŠ è½½: {segment_dir.name}")

        with open(corpus_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                if not line.strip():
                    continue

                try:
                    data = json.loads(line.strip())

                    # åˆ›å»ºæ–‡æ¡£ - å¤„ç†metadataä»¥é¿å…è¿‡é•¿é—®é¢˜
                    original_metadata = data.get('metadata', {})
                    metadata = {
                        'id': data.get('id', f'{segment_dir.name}_doc_{line_num}'),
                        'title': data.get('title', ''),
                        'source': data.get('source', ''),
                        'game': self.config.game_name,
                        'segment_id': segment_dir.name,
                    }

                    # å¤„ç†åŸå§‹metadataï¼Œå‹ç¼©entitiesä¿¡æ¯
                    for key, value in original_metadata.items():
                        if key == 'entities' and isinstance(value, list):
                            # åªä¿ç•™entitiesçš„textå­—æ®µï¼Œå¤§å¹…å‡å°‘metadataé•¿åº¦
                            entity_texts = []
                            for entity in value:
                                if isinstance(entity, dict) and entity.get('text'):
                                    entity_texts.append(entity.get('text', ''))
                            metadata['entity_texts'] = entity_texts
                        else:
                            metadata[key] = value

                    doc = Document(text=data.get('contents', ''), metadata=metadata)
                    doc.id_ = metadata['id']
                    self.documents.append(doc)

                except json.JSONDecodeError as e:
                    if self.config.verbose:
                        print(f"âš ï¸ {segment_dir.name}ç¬¬{line_num}è¡Œè§£æå¤±è´¥: {e}")

    def _print_document_stats(self):
        """æ‰“å°æ–‡æ¡£ç»Ÿè®¡ä¿¡æ¯"""
        segment_stats = {}
        for doc in self.documents:
            segment = doc.metadata.get('segment_id', 'unknown')
            segment_stats[segment] = segment_stats.get(segment, 0) + 1

        print(f"âœ… åŠ è½½æ–‡æ¡£æ€»æ•°: {len(self.documents)}")
        print("ğŸ“Š åˆ†æ®µç»Ÿè®¡:")
        for segment, count in sorted(segment_stats.items()):
            label = " (æ—¶é—´æ— å…³)" if segment == 'segment_timeless' or segment == -1 else ""
            print(f"   {segment}: {count}{label}")

        # æ—¶é—´æ— å…³æ•°æ®çŠ¶æ€æç¤º
        has_timeless = 'segment_timeless' in segment_stats or -1 in segment_stats
        if self.config.include_timeless and has_timeless:
            print("ğŸ• å·²åŒ…å«æ—¶é—´æ— å…³æ•°æ®")
        elif self.config.include_timeless and not has_timeless:
            print("âš ï¸ æœªæ‰¾åˆ°æ—¶é—´æ— å…³æ•°æ®")
        elif not self.config.include_timeless and has_timeless:
            print("â„¹ï¸ æ„å¤–åŠ è½½äº†æ—¶é—´æ— å…³æ•°æ®")

    def initialize(self) -> bool:
        """åˆå§‹åŒ–pipeline"""
        try:
            # åŠ è½½æ–‡æ¡£
            if not self.load_documents():
                return False

            # æ„å»ºç´¢å¼•
            if not self.retriever.build_index(self.documents):
                return False

            if self.config.verbose:
                print("âœ… RAG Pipelineåˆå§‹åŒ–å®Œæˆ")
            return True
        except Exception as e:
            if self.config.verbose:
                print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def query(self, question: str) -> Dict[str, Any]:
        """æ‰§è¡ŒæŸ¥è¯¢"""
        start_time = time.time()

        if self.config.verbose:
            print(f"ğŸ” æŸ¥è¯¢: {question}")

        # æ£€ç´¢æ–‡æ¡£
        docs = self.retriever.retrieve(question)

        if self.config.verbose:
            print(f"ğŸ“„ æ£€ç´¢åˆ° {len(docs)} ä¸ªæ–‡æ¡£")
            for i, doc in enumerate(docs, 1):
                metadata = doc.get('metadata', {})
                title = metadata.get('title', 'Unknown')
                segment = metadata.get('segment_id', 'Unknown')
                score = doc.get('score', 0.0)
                print(f"   {i}. {title} ({segment}, {score:.3f})")

        # ç”Ÿæˆå›ç­”
        answer = self.generator.generate(question, docs)

        # æ„å»ºç»“æœ
        result = {
            'question': question,
            'answer': answer,
            'retrieved_docs': docs,
            'retrieved_doc_ids': [doc.get('id', '') for doc in docs],
            'processing_time': time.time() - start_time,
            'timestamp': datetime.now().isoformat(),
            'config': {
                'game': self.config.game_name,
                'embedding_model': self.config.embedding_model,
                'llm_model': self.config.llm_model,
                'segment_id': self.config.target_segment_id
            }
        }

        if self.config.verbose:
            print(f"ğŸ’¡ å›ç­”: {answer}")
            print(f"â±ï¸ è€—æ—¶: {result['processing_time']:.2f}ç§’")

        return result

    def batch_query(self, questions: List[str], output_file: str = None) -> List[Dict[str, Any]]:
        """æ‰¹é‡æŸ¥è¯¢"""
        total = len(questions)
        results = []

        if self.config.verbose:
            print(f"ğŸ“ æ‰¹é‡æŸ¥è¯¢å¼€å§‹ï¼Œå…± {total} ä¸ªé—®é¢˜")

        for i, question in enumerate(questions):
            if self.config.verbose:
                print(f"\n--- é—®é¢˜ {i+1}/{total} ---")
                print(f"é—®é¢˜: {question[:60]}...")

            try:
                result = self.query(question)
                result['question_index'] = i
                results.append(result)

                # ä¿å­˜åˆ°æ–‡ä»¶
                if output_file:
                    with open(output_file, 'a', encoding='utf-8') as f:
                        f.write(json.dumps(result, ensure_ascii=False) + '\n')

            except Exception as e:
                if self.config.verbose:
                    print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
                error_result = {
                    'question': question,
                    'question_index': i,
                    'answer': f"æŸ¥è¯¢å¤±è´¥: {str(e)}",
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                }
                results.append(error_result)

                if output_file:
                    with open(output_file, 'a', encoding='utf-8') as f:
                        f.write(json.dumps(error_result, ensure_ascii=False) + '\n')

        if self.config.verbose:
            print(f"\nâœ… æ‰¹é‡æŸ¥è¯¢å®Œæˆï¼Œå¤„ç† {len(results)} ä¸ªé—®é¢˜")

        return results

    def batch_evaluate(self, qa_pairs: List[Dict[str, Any]], output_file: str = None) -> List[Dict[str, Any]]:
        """æ‰¹é‡è¯„ä¼°ï¼ˆä½¿ç”¨QAå¯¹ï¼ŒåŒ…å«æ ‡å‡†ç­”æ¡ˆå’Œæ–‡æ¡£IDï¼‰"""
        total = len(qa_pairs)
        results = []

        if self.config.verbose:
            print(f"ğŸ“ æ‰¹é‡è¯„ä¼°å¼€å§‹ï¼Œå…± {total} ä¸ªé—®ç­”å¯¹")

        for i, qa_pair in enumerate(qa_pairs):
            question = qa_pair['question']
            ground_truth_answer = qa_pair['ground_truth_answer']
            ground_truth_doc_ids = qa_pair['ground_truth_doc_ids']

            if self.config.verbose:
                print(f"\n--- é—®ç­”å¯¹ {i+1}/{total} ---")
                print(f"é—®é¢˜: {question[:60]}...")

            try:
                # æ‰§è¡ŒRAGæŸ¥è¯¢
                result = self.query(question)

                # æ·»åŠ è¯„ä¼°ç›¸å…³ä¿¡æ¯
                result.update({
                    'question_index': i,
                    'ground_truth_answer': ground_truth_answer,
                    'ground_truth_doc_ids': ground_truth_doc_ids,
                    'ground_truth_docs': qa_pair['ground_truth_docs'],
                    # ä¿ç•™åŸæœ‰çš„retrieved_doc_idsï¼ˆRAGæ£€ç´¢åˆ°çš„ï¼‰
                    # resultä¸­å·²ç»åŒ…å«äº†retrieved_doc_ids
                })

                results.append(result)

                # ä¿å­˜åˆ°æ–‡ä»¶
                if output_file:
                    with open(output_file, 'a', encoding='utf-8') as f:
                        f.write(json.dumps(result, ensure_ascii=False) + '\n')

            except Exception as e:
                if self.config.verbose:
                    print(f"âŒ è¯„ä¼°å¤±è´¥: {e}")
                error_result = {
                    'question': question,
                    'question_index': i,
                    'answer': f"è¯„ä¼°å¤±è´¥: {str(e)}",
                    'error': str(e),
                    'timestamp': datetime.now().isoformat(),
                    'ground_truth_answer': ground_truth_answer,
                    'ground_truth_doc_ids': ground_truth_doc_ids,
                    'retrieved_doc_ids': []
                }
                results.append(error_result)

                if output_file:
                    with open(output_file, 'a', encoding='utf-8') as f:
                        f.write(json.dumps(error_result, ensure_ascii=False) + '\n')

        if self.config.verbose:
            print(f"\nâœ… æ‰¹é‡è¯„ä¼°å®Œæˆï¼Œå¤„ç† {len(results)} ä¸ªé—®ç­”å¯¹")

        return results

    def load_qa_pairs(self, segment_id: int = None) -> List[Dict[str, Any]]:
        """åŠ è½½QAé—®ç­”å¯¹ï¼ˆåŒ…å«æ ‡å‡†ç­”æ¡ˆå’Œæ ‡å‡†æ–‡æ¡£IDï¼‰"""
        if segment_id is None:
            segment_id = self.config.target_segment_id

        if segment_id is None:
            raise ValueError("å¿…é¡»æŒ‡å®šåˆ†æ®µID")

        # ä½¿ç”¨æ–°çš„ QA æ•°æ®è·¯å¾„: data/{æ¸¸æˆåç§°}/segments/segment_{id}
        qa_dir = Path(self.config.qa_data_dir) / self.config.game_name / "segments" / f"segment_{segment_id}"
        qa_filename = "generated_qa_pairs.jsonl"
        qa_file = qa_dir / qa_filename

        if not qa_file.exists():
            error_msg = f"âŒ QAæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {qa_file}"
            if self.config.verbose:
                print(error_msg)
            raise FileNotFoundError(error_msg)

        if self.config.verbose:
            print(f"ğŸ“ ä½¿ç”¨QAæ•°æ®: {qa_file}")

        qa_pairs = []
        try:
            with open(qa_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        try:
                            data = json.loads(line.strip())
                            question = data.get('question', '').strip()
                            if question:
                                # æå–æ ‡å‡†ç­”æ¡ˆå’Œæ ‡å‡†æ–‡æ¡£ID
                                ground_truth_answer = data.get('answer', '')
                                ground_truth_docs = data.get('retrieved_docs', [])
                                ground_truth_doc_ids = [doc.get('id', '') for doc in ground_truth_docs]

                                qa_pairs.append({
                                    'question': question,
                                    'ground_truth_answer': ground_truth_answer,
                                    'ground_truth_doc_ids': ground_truth_doc_ids,
                                    'ground_truth_docs': ground_truth_docs,
                                    'original_data': data  # ä¿ç•™å®Œæ•´åŸå§‹æ•°æ®ç”¨äºå…¶ä»–åˆ†æ
                                })
                        except json.JSONDecodeError:
                            continue

            if self.config.verbose:
                print(f"âœ… åŠ è½½äº† {len(qa_pairs)} ä¸ªQAé—®ç­”å¯¹")

        except Exception as e:
            if self.config.verbose:
                print(f"âŒ åŠ è½½QAæ•°æ®å¤±è´¥: {e}")

        return qa_pairs

    def load_qa_questions(self, segment_id: int = None) -> List[str]:
        """åŠ è½½QAé—®é¢˜ï¼ˆå‘åå…¼å®¹ï¼‰"""
        qa_pairs = self.load_qa_pairs(segment_id)
        return [pair['question'] for pair in qa_pairs]
