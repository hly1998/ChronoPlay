# -*- coding: utf-8 -*-
"""
ç‹¬ç«‹æ£€ç´¢Pipeline
å°†æ£€ç´¢è¿‡ç¨‹ä¸ç”Ÿæˆè¿‡ç¨‹è§£è€¦ï¼Œæ”¯æŒä¸€æ¬¡æ£€ç´¢ï¼Œå¤šæ¬¡ç”Ÿæˆçš„å®éªŒæ¨¡å¼
"""

import json
import time
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

from llama_index.core import Document

from .retriever import VectorRetriever
from .bm25_retriever import BM25Retriever


class RetrievalPipeline:
    """ç‹¬ç«‹çš„æ£€ç´¢Pipeline"""

    def __init__(self, config):
        self.config = config
        self.documents = []

        # æ ¹æ®æ£€ç´¢æ–¹æ³•é€‰æ‹©æ£€ç´¢å™¨
        if hasattr(config, 'retrieval_method') and config.retrieval_method == 'bm25':
            if hasattr(config, 'bm25_k1') and hasattr(config, 'bm25_b'):
                self.retriever = BM25Retriever(config, k1=config.bm25_k1, b=config.bm25_b)
            else:
                self.retriever = BM25Retriever(config)
        else:
            self.retriever = VectorRetriever(config)

    def load_documents(self) -> bool:
        """åŠ è½½æ–‡æ¡£"""
        corpus_dir = Path(self.config.corpus_dir) / self.config.game_name / "corpus"
        if not corpus_dir.exists():
            if self.config.verbose:
                print(f"âŒ è¯­æ–™åº“ç›®å½•ä¸å­˜åœ¨: {corpus_dir}")
            return False

        # ç¡®å®šè¦åŠ è½½çš„åˆ†æ®µç›®å½•
        segment_dirs = self._get_segment_dirs(corpus_dir)

        # åŠ è½½æ–‡æ¡£
        self.documents = []
        for segment_dir in segment_dirs:
            self._load_segment_documents(segment_dir)

        if self.config.verbose:
            self._print_document_stats()

        return len(self.documents) > 0

    def _get_segment_dirs(self, corpus_dir: Path) -> List[Path]:
        """è·å–è¦åŠ è½½çš„åˆ†æ®µç›®å½•"""
        if self.config.target_segment_id:
            # åŠ è½½æŒ‡å®šåˆ†æ®µ
            dirs = [corpus_dir / f"segment_{self.config.target_segment_id}"]
            if self.config.include_timeless:
                timeless_dir = corpus_dir / "segment_timeless"
                if timeless_dir.exists():
                    dirs.append(timeless_dir)
        else:
            # åŠ è½½æ‰€æœ‰åˆ†æ®µ
            dirs = [d for d in corpus_dir.iterdir() if d.is_dir() and d.name.startswith('segment_')]
            if self.config.include_timeless:
                timeless_dir = corpus_dir / "segment_timeless"
                if timeless_dir.exists() and timeless_dir not in dirs:
                    dirs.append(timeless_dir)
        return dirs

    def _load_segment_documents(self, segment_dir: Path):
        """åŠ è½½å•ä¸ªåˆ†æ®µçš„æ–‡æ¡£"""
        corpus_file = segment_dir / "corpus.jsonl"
        if not corpus_file.exists():
            return

        with open(corpus_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                if not line.strip():
                    continue

                try:
                    data = json.loads(line.strip())

                    # åˆ›å»ºæ–‡æ¡£ - å¤„ç†metadataä»¥é¿å…è¿‡é•¿é—®é¢˜
                    original_metadata = data.get('metadata', {})
                    metadata = {
                        'id': data.get('id', f'{segment_dir.name}_doc_{line_num}'),
                        'title': data.get('title', ''),
                        'source': data.get('source', ''),
                        'game': self.config.game_name,
                        'segment_id': segment_dir.name,
                    }

                    # å¤„ç†åŸå§‹metadataï¼Œå‹ç¼©entitiesä¿¡æ¯
                    for key, value in original_metadata.items():
                        if key == 'entities' and isinstance(value, list):
                            # åªä¿ç•™entitiesçš„textå­—æ®µï¼Œå¤§å¹…å‡å°‘metadataé•¿åº¦
                            entity_texts = []
                            for entity in value:
                                if isinstance(entity, dict) and entity.get('text'):
                                    entity_texts.append(entity.get('text', ''))
                            metadata['entity_texts'] = entity_texts
                        else:
                            metadata[key] = value

                    doc = Document(text=data.get('contents', ''), metadata=metadata)
                    doc.id_ = metadata['id']
                    self.documents.append(doc)

                except json.JSONDecodeError as e:
                    if self.config.verbose:
                        print(f"âš ï¸ {segment_dir.name}ç¬¬{line_num}è¡Œè§£æå¤±è´¥: {e}")

    def _print_document_stats(self):
        """æ‰“å°æ–‡æ¡£ç»Ÿè®¡ä¿¡æ¯"""
        segment_stats = {}
        for doc in self.documents:
            segment = doc.metadata.get('segment_id', 'unknown')
            segment_stats[segment] = segment_stats.get(segment, 0) + 1

        print(f"âœ… åŠ è½½ {len(self.documents)} ä¸ªæ–‡æ¡£")

    def initialize(self) -> bool:
        """åˆå§‹åŒ–æ£€ç´¢pipeline"""
        try:
            # åŠ è½½æ–‡æ¡£
            if not self.load_documents():
                return False

            # æ„å»ºç´¢å¼•
            if not self.retriever.build_index(self.documents):
                return False

            return True
        except Exception as e:
            if self.config.verbose:
                print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def retrieve_single(self, question: str) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªé—®é¢˜çš„æ£€ç´¢"""
        start_time = time.time()

        if self.config.verbose:
            print(f"ğŸ” æ£€ç´¢é—®é¢˜: {question}")

        # æ£€ç´¢æ–‡æ¡£
        docs = self.retriever.retrieve(question)

        if self.config.verbose:
            print(f"ğŸ“„ æ£€ç´¢åˆ° {len(docs)} ä¸ªæ–‡æ¡£")
            for i, doc in enumerate(docs, 1):
                metadata = doc.get('metadata', {})
                title = metadata.get('title', 'Unknown')
                segment = metadata.get('segment_id', 'Unknown')
                score = doc.get('score', 0.0)
                print(f"   {i}. {title} ({segment}, {score:.3f})")

        # æ„å»ºæ£€ç´¢ç»“æœ
        result = {
            'question': question,
            'retrieved_docs': docs,
            'retrieved_doc_ids': [doc.get('id', '') for doc in docs],
            'retrieval_time': time.time() - start_time,
            'timestamp': datetime.now().isoformat(),
            'retrieval_config': self._get_retrieval_config()
        }

        if self.config.verbose:
            print(f"â±ï¸ æ£€ç´¢è€—æ—¶: {result['retrieval_time']:.2f}ç§’")

        return result

    def batch_retrieve(self, questions: List[str], output_file: str = None) -> List[Dict[str, Any]]:
        """æ‰¹é‡æ£€ç´¢ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼šä¸€æ¬¡æ€§è·å–æ‰€æœ‰embeddingsï¼‰"""
        total = len(questions)
        results = []

        try:
            # ä½¿ç”¨æ‰¹é‡æ£€ç´¢æ–¹æ³•
            start_time = time.time()
            batch_results = self.retriever.batch_retrieve(questions)
            batch_time = time.time() - start_time

            if self.config.verbose:
                print(f"âœ… æ‰¹é‡æ£€ç´¢å®Œæˆ: {total} ä¸ªé—®é¢˜, è€—æ—¶ {batch_time:.2f}s")

            # æ„å»ºè¯¦ç»†ç»“æœ
            for i, (question, docs) in enumerate(zip(questions, batch_results)):

                result = {
                    'question': question,
                    'retrieved_docs': docs,
                    'retrieved_doc_ids': [doc.get('id', '') for doc in docs],
                    'retrieval_time': batch_time / total,  # åˆ†æ‘Šæ—¶é—´
                    'timestamp': datetime.now().isoformat(),
                    'question_index': i,
                    'retrieval_config': {
                        **self._get_retrieval_config(),
                        'batch_mode': True
                    }
                }

                results.append(result)

                # ä¿å­˜åˆ°æ–‡ä»¶
                if output_file:
                    with open(output_file, 'a', encoding='utf-8') as f:
                        f.write(json.dumps(result, ensure_ascii=False) + '\n')

        except Exception as e:
            if self.config.verbose:
                print(f"âš ï¸ æ‰¹é‡æ£€ç´¢å¤±è´¥ï¼Œå›é€€åˆ°é€ä¸ªæ£€ç´¢: {e}")

            # å›é€€åˆ°åŸæ¥çš„é€ä¸ªæ£€ç´¢æ–¹å¼
            for i, question in enumerate(questions):

                try:
                    result = self.retrieve_single(question)
                    result['question_index'] = i
                    results.append(result)

                    # ä¿å­˜åˆ°æ–‡ä»¶
                    if output_file:
                        with open(output_file, 'a', encoding='utf-8') as f:
                            f.write(json.dumps(result, ensure_ascii=False) + '\n')

                except Exception as e:
                    if self.config.verbose:
                        print(f"âŒ æ£€ç´¢å¤±è´¥: {e}")
                    error_result = {
                        'question': question,
                        'question_index': i,
                        'retrieved_docs': [],
                        'retrieved_doc_ids': [],
                        'error': str(e),
                        'timestamp': datetime.now().isoformat()
                    }
                    results.append(error_result)

                    if output_file:
                        with open(output_file, 'a', encoding='utf-8') as f:
                            f.write(json.dumps(error_result, ensure_ascii=False) + '\n')

        if self.config.verbose:
            print(f"\nâœ… æ‰¹é‡æ£€ç´¢å®Œæˆï¼Œå¤„ç† {len(results)} ä¸ªé—®é¢˜")

        return results

    def batch_retrieve_qa_pairs(self, qa_pairs: List[Dict[str, Any]], output_file: str = None) -> List[Dict[str, Any]]:
        """æ‰¹é‡æ£€ç´¢QAå¯¹ï¼ˆåŒ…å«æ ‡å‡†ç­”æ¡ˆä¿¡æ¯ï¼Œä¾¿äºåç»­è¯„ä¼°ï¼‰ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼šä¸€æ¬¡æ€§è·å–æ‰€æœ‰embeddingsï¼‰"""
        total = len(qa_pairs)
        results = []

        try:
            # æå–æ‰€æœ‰é—®é¢˜
            questions = [qa_pair['question'] for qa_pair in qa_pairs]

            # ä½¿ç”¨æ‰¹é‡æ£€ç´¢æ–¹æ³•
            start_time = time.time()
            batch_results = self.retriever.batch_retrieve(questions)
            batch_time = time.time() - start_time

            if self.config.verbose:
                print(f"âœ… æ‰¹é‡æ£€ç´¢å®Œæˆ: {total} ä¸ªQAå¯¹, è€—æ—¶ {batch_time:.2f}s")

            # æ„å»ºè¯¦ç»†ç»“æœ
            for i, (qa_pair, docs) in enumerate(zip(qa_pairs, batch_results)):

                question = qa_pair['question']

                result = {
                    'question': question,
                    'retrieved_docs': docs,
                    'retrieved_doc_ids': [doc.get('id', '') for doc in docs],
                    'retrieval_time': batch_time / total,  # åˆ†æ‘Šæ—¶é—´
                    'timestamp': datetime.now().isoformat(),
                    'question_index': i,
                    'ground_truth_answer': qa_pair['ground_truth_answer'],
                    'ground_truth_doc_ids': qa_pair['ground_truth_doc_ids'],
                    'ground_truth_docs': qa_pair['ground_truth_docs'],
                    'original_qa_data': qa_pair.get('original_data', {}),
                    'retrieval_config': {
                        **self._get_retrieval_config(),
                        'batch_mode': True
                    }
                }

                results.append(result)

                # ä¿å­˜åˆ°æ–‡ä»¶
                if output_file:
                    with open(output_file, 'a', encoding='utf-8') as f:
                        f.write(json.dumps(result, ensure_ascii=False) + '\n')

        except Exception as e:
            if self.config.verbose:
                print(f"âš ï¸ æ‰¹é‡æ£€ç´¢å¤±è´¥ï¼Œå›é€€åˆ°é€ä¸ªæ£€ç´¢: {e}")

            # å›é€€åˆ°åŸæ¥çš„é€ä¸ªæ£€ç´¢æ–¹å¼
            for i, qa_pair in enumerate(qa_pairs):
                question = qa_pair['question']

                try:
                    # æ‰§è¡Œæ£€ç´¢
                    result = self.retrieve_single(question)

                    # æ·»åŠ QAå¯¹ç›¸å…³ä¿¡æ¯ï¼ˆä¾¿äºåç»­ç”Ÿæˆå’Œè¯„ä¼°ï¼‰
                    result.update({
                        'question_index': i,
                        'ground_truth_answer': qa_pair['ground_truth_answer'],
                        'ground_truth_doc_ids': qa_pair['ground_truth_doc_ids'],
                        'ground_truth_docs': qa_pair['ground_truth_docs'],
                        'original_qa_data': qa_pair.get('original_data', {})
                    })

                    results.append(result)

                    # ä¿å­˜åˆ°æ–‡ä»¶
                    if output_file:
                        with open(output_file, 'a', encoding='utf-8') as f:
                            f.write(json.dumps(result, ensure_ascii=False) + '\n')

                except Exception as e:
                    if self.config.verbose:
                        print(f"âŒ æ£€ç´¢å¤±è´¥: {e}")
                    error_result = {
                        'question': question,
                        'question_index': i,
                        'retrieved_docs': [],
                        'retrieved_doc_ids': [],
                        'error': str(e),
                        'timestamp': datetime.now().isoformat(),
                        'ground_truth_answer': qa_pair['ground_truth_answer'],
                        'ground_truth_doc_ids': qa_pair['ground_truth_doc_ids']
                    }
                    results.append(error_result)

                    if output_file:
                        with open(output_file, 'a', encoding='utf-8') as f:
                            f.write(json.dumps(error_result, ensure_ascii=False) + '\n')

        return results

    def load_qa_pairs(self, segment_id: int = None) -> List[Dict[str, Any]]:
        """åŠ è½½QAé—®ç­”å¯¹ï¼ˆä»ç”Ÿæˆçš„æ•°æ®ä¸­æå–ï¼‰"""
        if segment_id is None:
            segment_id = self.config.target_segment_id

        if segment_id is None:
            raise ValueError("å¿…é¡»æŒ‡å®šåˆ†æ®µID")

        # ä½¿ç”¨æ–°çš„ QA æ•°æ®è·¯å¾„: data/{æ¸¸æˆåç§°}/segments/segment_{id}
        qa_dir = Path(self.config.qa_data_dir) / self.config.game_name / "segments" / f"segment_{segment_id}"
        qa_filename = "generated_qa_pairs.jsonl"
        qa_file = qa_dir / qa_filename

        if not qa_file.exists():
            error_msg = f"âŒ QAæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {qa_file}"
            if self.config.verbose:
                print(error_msg)
            raise FileNotFoundError(error_msg)

        qa_pairs = []
        try:
            with open(qa_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        try:
                            data = json.loads(line.strip())
                            question = data.get('question', '').strip()
                            if question:
                                # æå–æ ‡å‡†ç­”æ¡ˆå’Œæ ‡å‡†æ–‡æ¡£ID
                                ground_truth_answer = data.get('answer', '')
                                ground_truth_docs = data.get('retrieved_docs', [])
                                ground_truth_doc_ids = [doc.get('id', '') for doc in ground_truth_docs]

                                qa_pairs.append({
                                    'question': question,
                                    'ground_truth_answer': ground_truth_answer,
                                    'ground_truth_doc_ids': ground_truth_doc_ids,
                                    'ground_truth_docs': ground_truth_docs,
                                    'original_data': data  # ä¿ç•™å®Œæ•´åŸå§‹æ•°æ®
                                })
                        except json.JSONDecodeError:
                            continue

        except Exception as e:
            if self.config.verbose:
                print(f"âŒ åŠ è½½QAæ•°æ®å¤±è´¥: {e}")

        return qa_pairs

    def _get_retrieval_config(self) -> Dict[str, Any]:
        """è·å–æ£€ç´¢é…ç½®ä¿¡æ¯"""
        config = {
            'game': self.config.game_name,
            'segment_id': self.config.target_segment_id,
            'top_k': self.config.top_k,
            'include_timeless': self.config.include_timeless
        }

        # æ ¹æ®æ£€ç´¢æ–¹æ³•æ·»åŠ ä¸åŒçš„é…ç½®ä¿¡æ¯
        if hasattr(self.config, 'retrieval_method') and self.config.retrieval_method == 'bm25':
            config.update({
                'retrieval_method': 'bm25',
                'bm25_k1': getattr(self.config, 'bm25_k1', 1.2),
                'bm25_b': getattr(self.config, 'bm25_b', 0.75)
            })
        else:
            config.update({
                'retrieval_method': 'vector',
                'embedding_model': getattr(self.config, 'embedding_model', 'unknown')
            })

        return config
