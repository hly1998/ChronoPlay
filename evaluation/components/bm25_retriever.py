# -*- coding: utf-8 -*-
"""
BM25æ£€ç´¢å™¨ç»„ä»¶
åŸºäºè¯é¢‘-é€†æ–‡æ¡£é¢‘ç‡çš„ä¼ ç»Ÿæ£€ç´¢æ–¹æ³•
"""

import json
import pickle
from pathlib import Path
from typing import List, Dict, Any, Optional
from collections import defaultdict, Counter
import math
import re
import jieba
from tqdm import tqdm

from llama_index.core import Document


class BM25Retriever:
    """BM25æ£€ç´¢å™¨å®ç°"""

    def __init__(self, config, k1: float = 1.2, b: float = 0.75):
        """
        åˆå§‹åŒ–BM25æ£€ç´¢å™¨

        Args:
            config: RAGConfigæˆ–RetrievalConfig
            k1: BM25å‚æ•°k1ï¼Œæ§åˆ¶è¯é¢‘é¥±å’Œåº¦
            b: BM25å‚æ•°bï¼Œæ§åˆ¶æ–‡æ¡£é•¿åº¦å½’ä¸€åŒ–ç¨‹åº¦
        """
        self.config = config
        self.k1 = k1
        self.b = b

        # BM25è®¡ç®—ç›¸å…³
        self.documents = []
        self.doc_freqs = []  # æ¯ä¸ªæ–‡æ¡£çš„è¯é¢‘å­—å…¸
        self.idf = {}  # è¯æ±‡çš„IDFå€¼
        self.doc_lens = []  # æ¯ä¸ªæ–‡æ¡£çš„é•¿åº¦
        self.avgdl = 0.0  # å¹³å‡æ–‡æ¡£é•¿åº¦
        self.N = 0  # æ–‡æ¡£æ€»æ•°

    def _tokenize(self, text: str) -> List[str]:
        """
        åˆ†è¯å‡½æ•°ï¼Œæ”¯æŒä¸­è‹±æ–‡æ··åˆ

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            åˆ†è¯ç»“æœåˆ—è¡¨
        """
        if not text:
            return []

        # æ¸…ç†æ–‡æœ¬
        text = re.sub(r'[^\w\s\u4e00-\u9fff]', ' ', text)
        text = text.lower()

        # ä½¿ç”¨jiebaåˆ†è¯å¤„ç†ä¸­æ–‡ï¼Œä¿ç•™è‹±æ–‡å•è¯
        tokens = []
        words = jieba.lcut(text)

        for word in words:
            word = word.strip()
            if len(word) > 1:  # è¿‡æ»¤å•å­—ç¬¦
                tokens.append(word)

        return tokens

    def _compute_idf(self):
        """è®¡ç®—æ‰€æœ‰è¯æ±‡çš„IDFå€¼"""
        df = defaultdict(int)  # æ–‡æ¡£é¢‘ç‡

        # ç»Ÿè®¡æ¯ä¸ªè¯å‡ºç°åœ¨å¤šå°‘ä¸ªæ–‡æ¡£ä¸­
        for doc_freq in self.doc_freqs:
            for word in doc_freq.keys():
                df[word] += 1

        # è®¡ç®—IDF
        self.idf = {}
        for word, freq in df.items():
            self.idf[word] = math.log(self.N / freq)

    def build_index(self, documents: List[Document]) -> bool:
        """
        æ„å»ºBM25ç´¢å¼•

        Args:
            documents: æ–‡æ¡£åˆ—è¡¨

        Returns:
            æ˜¯å¦æ„å»ºæˆåŠŸ
        """
        # ç”Ÿæˆç´¢å¼•è·¯å¾„
        index_name = self._get_index_name()
        index_path = Path(self.config.index_dir) / self.config.game_name / index_name

        # å°è¯•åŠ è½½å·²æœ‰ç´¢å¼•
        if index_path.exists() and not self.config.force_rebuild:
            if self._load_existing_index(index_path):
                return True

        # æ„å»ºæ–°ç´¢å¼•
        return self._build_new_index(documents, index_path)

    def _get_index_name(self) -> str:
        """ç”Ÿæˆç´¢å¼•åç§°"""
        if self.config.target_segment_id:
            suffix = "_with_timeless" if self.config.include_timeless else ""
            return f"bm25/segment_{self.config.target_segment_id}{suffix}"
        return "bm25/full_corpus"

    def _load_existing_index(self, index_path: Path) -> bool:
        """åŠ è½½å·²æœ‰ç´¢å¼•"""
        try:
            if self.config.verbose:
                print(f"ğŸ“‚ åŠ è½½å·²æœ‰BM25ç´¢å¼•: {index_path.name}")

            # åŠ è½½ç´¢å¼•æ–‡ä»¶
            with open(index_path / "bm25_index.pkl", 'rb') as f:
                index_data = pickle.load(f)

            self.documents = index_data['documents']
            self.doc_freqs = index_data['doc_freqs']
            self.idf = index_data['idf']
            self.doc_lens = index_data['doc_lens']
            self.avgdl = index_data['avgdl']
            self.N = index_data['N']

            if self.config.verbose:
                print(f"âœ… BM25ç´¢å¼•åŠ è½½æˆåŠŸ: {self.N} æ–‡æ¡£")
            return True
        except Exception as e:
            if self.config.verbose:
                print(f"âš ï¸ BM25ç´¢å¼•åŠ è½½å¤±è´¥: {e}")
            return False

    def _build_new_index(self, documents: List[Document], index_path: Path) -> bool:
        """æ„å»ºæ–°çš„BM25ç´¢å¼•"""
        try:
            self.documents = documents
            self.N = len(documents)
            self.doc_freqs = []
            self.doc_lens = []

            # ä¸ºæ¯ä¸ªæ–‡æ¡£è®¡ç®—è¯é¢‘
            for doc in tqdm(documents, desc="BM25ç´¢å¼•", disable=not self.config.verbose):
                # åˆ†è¯
                tokens = self._tokenize(doc.text)

                # è®¡ç®—è¯é¢‘
                word_freq = Counter(tokens)
                self.doc_freqs.append(dict(word_freq))
                self.doc_lens.append(len(tokens))

            # è®¡ç®—å¹³å‡æ–‡æ¡£é•¿åº¦
            self.avgdl = sum(self.doc_lens) / len(self.doc_lens)

            # è®¡ç®—IDF
            self._compute_idf()

            # ä¿å­˜ç´¢å¼•
            index_path.mkdir(parents=True, exist_ok=True)

            index_data = {
                'documents': self.documents,
                'doc_freqs': self.doc_freqs,
                'idf': self.idf,
                'doc_lens': self.doc_lens,
                'avgdl': self.avgdl,
                'N': self.N
            }

            with open(index_path / "bm25_index.pkl", 'wb') as f:
                pickle.dump(index_data, f)

            # ä¿å­˜å…ƒæ•°æ®
            metadata = {
                'k1': self.k1,
                'b': self.b,
                'num_documents': self.N,
                'num_vocab': len(self.idf),
                'avg_doc_len': self.avgdl
            }

            with open(index_path / "metadata.json", 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)

            if self.config.verbose:
                print(f"âœ… BM25ç´¢å¼•æ„å»ºå®Œæˆ: {self.N} æ–‡æ¡£")

            return True
        except Exception as e:
            if self.config.verbose:
                print(f"âŒ BM25ç´¢å¼•æ„å»ºå¤±è´¥: {e}")
            return False

    def _bm25_score(self, query_tokens: List[str], doc_idx: int) -> float:
        """
        è®¡ç®—å•ä¸ªæ–‡æ¡£çš„BM25å¾—åˆ†

        Args:
            query_tokens: æŸ¥è¯¢åˆ†è¯ç»“æœ
            doc_idx: æ–‡æ¡£ç´¢å¼•

        Returns:
            BM25å¾—åˆ†
        """
        score = 0.0
        doc_freq = self.doc_freqs[doc_idx]
        doc_len = self.doc_lens[doc_idx]

        for token in query_tokens:
            if token in doc_freq and token in self.idf:
                tf = doc_freq[token]
                idf = self.idf[token]

                # BM25å…¬å¼
                numerator = tf * (self.k1 + 1)
                denominator = tf + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)
                score += idf * numerator / denominator

        return score

    def retrieve(self, query: str, top_k: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        æ£€ç´¢ç›¸å…³æ–‡æ¡£

        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            top_k: è¿”å›top-kç»“æœï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„å€¼

        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        if not self.documents:
            raise ValueError("BM25ç´¢å¼•æœªåˆå§‹åŒ–")

        if top_k is None:
            top_k = self.config.top_k

        # æŸ¥è¯¢åˆ†è¯
        query_tokens = self._tokenize(query)
        if not query_tokens:
            return []

        # è®¡ç®—æ‰€æœ‰æ–‡æ¡£çš„BM25å¾—åˆ†
        scores = []
        for i in range(self.N):
            score = self._bm25_score(query_tokens, i)
            scores.append((score, i))

        # æŒ‰å¾—åˆ†æ’åºï¼Œå–top-k
        scores.sort(reverse=True)
        top_scores = scores[:top_k]

        # æ„å»ºç»“æœ
        results = []
        for score, doc_idx in top_scores:
            doc = self.documents[doc_idx]
            results.append({
                'id': doc.id_,
                'content': doc.text,
                'metadata': doc.metadata,
                'score': score
            })

        return results

    def batch_retrieve(self, queries: List[str], top_k: Optional[int] = None) -> List[List[Dict[str, Any]]]:
        """
        æ‰¹é‡æ£€ç´¢

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨
            top_k: è¿”å›top-kç»“æœï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„å€¼

        Returns:
            æ¯ä¸ªæŸ¥è¯¢å¯¹åº”çš„æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        if top_k is None:
            top_k = self.config.top_k

        results = []

        for i, query in enumerate(tqdm(queries, desc="BM25æ£€ç´¢", disable=not self.config.verbose)):

            try:
                query_results = self.retrieve(query, top_k)
                results.append(query_results)
            except Exception:
                results.append([])

        return results
