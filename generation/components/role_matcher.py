"""è§’è‰²åŒ¹é…å™¨ - è´Ÿè´£ä¸ºé—®é¢˜æ¨¡æ¿åŒ¹é…åˆé€‚çš„ç©å®¶è§’è‰²"""

import json
import numpy as np
from typing import List, Dict, Any, Optional
from pathlib import Path
from sklearn.metrics.pairwise import cosine_similarity
from openai import OpenAI


class RoleMatcher:
    """è§’è‰²åŒ¹é…å™¨ç±»"""

    def __init__(self, role_data_file: str,
                 openai_client: Optional[OpenAI] = None,
                 use_semantic_matching: bool = True,
                 role_index_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–è§’è‰²åŒ¹é…å™¨

        Args:
            role_data_file: è§’è‰²æ•°æ®æ–‡ä»¶è·¯å¾„
            openai_client: OpenAIå®¢æˆ·ç«¯ï¼Œç”¨äºè¯­ä¹‰åŒ¹é…
            use_semantic_matching: æ˜¯å¦ä½¿ç”¨è¯­ä¹‰åŒ¹é…
            role_index_dir: è§’è‰²ç´¢å¼•å­˜å‚¨ç›®å½•ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤ä½ç½®
        """
        self.role_data_file = Path(role_data_file)
        self.roles_data = []
        self.openai_client = openai_client
        self.use_semantic_matching = use_semantic_matching

        # è®¾ç½®è§’è‰²ç´¢å¼•å­˜å‚¨ç›®å½•
        if role_index_dir:
            self.role_index_dir = Path(role_index_dir)
        else:
            # é»˜è®¤å­˜å‚¨ä½ç½®ï¼šè§’è‰²æ•°æ®æ–‡ä»¶åŒç›®å½•ä¸‹çš„role_indexå­ç›®å½•
            self.role_index_dir = self.role_data_file.parent / "role_index"

        # ç¡®ä¿ç´¢å¼•ç›®å½•å­˜åœ¨
        self.role_index_dir.mkdir(parents=True, exist_ok=True)

        # è¯­ä¹‰åŒ¹é…ç›¸å…³å±æ€§
        self.role_embeddings = []
        self.template_cache = {}  # ç¼“å­˜æ¨¡æ¿çš„åµŒå…¥å‘é‡
        self.role_embeddings_file = self.role_index_dir / "role_embeddings.npy"

        self._load_roles_data()
        self._build_topic_index()

        # å¦‚æœå¯ç”¨è¯­ä¹‰åŒ¹é…ï¼Œé¢„è®¡ç®—è§’è‰²åµŒå…¥
        if self.use_semantic_matching and self.openai_client:
            self._precompute_role_embeddings()

    def _load_roles_data(self):
        """åŠ è½½è§’è‰²æ•°æ®"""
        if not self.role_data_file.exists():
            raise FileNotFoundError(f"è§’è‰²æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.role_data_file}")

        try:
            with open(self.role_data_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line:
                        role_data = json.loads(line)
                        self.roles_data.append(role_data)

            print(f"âœ… æˆåŠŸåŠ è½½ {len(self.roles_data)} ä¸ªè§’è‰²æ•°æ®")
        except Exception as e:
            print(f"âŒ åŠ è½½è§’è‰²æ•°æ®å¤±è´¥: {e}")
            raise

    def _build_topic_index(self):
        """æ„å»ºè¯é¢˜ç´¢å¼•ï¼Œç”¨äºå¿«é€Ÿæ£€ç´¢"""
        self.topic_to_roles = {}

        for role in self.roles_data:
            source_topic = role.get('source_topic', '')
            if source_topic:
                # å¤„ç†å¤šä¸ªè¯é¢˜ï¼ˆç”¨|åˆ†éš”ï¼‰
                topics = [topic.strip() for topic in source_topic.split('|')]
                for topic in topics:
                    if topic not in self.topic_to_roles:
                        self.topic_to_roles[topic] = []
                    self.topic_to_roles[topic].append(role)

    def find_matching_role(self, template_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        ä¸ºç»™å®šçš„é—®é¢˜æ¨¡æ¿æ‰¾åˆ°æœ€åŒ¹é…çš„è§’è‰²

        Args:
            template_data: é—®é¢˜æ¨¡æ¿æ•°æ®

        Returns:
            åŒ¹é…çš„è§’è‰²æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›None
        """
        if not self.roles_data:
            return None

        # åªä½¿ç”¨è¯­ä¹‰åŒ¹é…ï¼Œå¤±è´¥æ—¶è¿”å›None
        if self.use_semantic_matching and len(self.role_embeddings) > 0:
            return self._semantic_matching(template_data)
        else:
            # å¦‚æœè¯­ä¹‰åŒ¹é…ä¸å¯ç”¨ï¼Œç›´æ¥è¿”å›None
            return None

    def _semantic_matching(self, template_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        ä½¿ç”¨è¯­ä¹‰åŒ¹é…æ‰¾åˆ°æœ€ä½³è§’è‰²

        Args:
            template_data: é—®é¢˜æ¨¡æ¿æ•°æ®

        Returns:
            æœ€åŒ¹é…çš„è§’è‰²æ•°æ®
        """

        # æ„å»ºæ¨¡æ¿çš„æ–‡æœ¬è¡¨ç¤º
        template_text = self._build_template_text_representation(template_data)
        template_id = template_data.get('id', str(hash(template_text)))

        # æ£€æŸ¥ç¼“å­˜
        if template_id in self.template_cache:
            template_embedding = self.template_cache[template_id]
        else:
            # è®¡ç®—æ¨¡æ¿çš„åµŒå…¥å‘é‡
            template_embedding = self._get_embedding(template_text)
            self.template_cache[template_id] = template_embedding

        # è®¡ç®—ä¸æ‰€æœ‰è§’è‰²çš„ç›¸ä¼¼åº¦
        similarities = cosine_similarity(
            template_embedding.reshape(1, -1),
            self.role_embeddings
        ).flatten()

        # æ‰¾åˆ°æœ€ç›¸ä¼¼çš„è§’è‰²
        best_role_idx = np.argmax(similarities)
        best_similarity = similarities[best_role_idx]

        # è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œé¿å…åŒ¹é…åº¦è¿‡ä½çš„è§’è‰²
        if best_similarity < 0.6:  # å¯è°ƒæ•´çš„é˜ˆå€¼
            print(f"ğŸ® æœ€ä½³åŒ¹é…ç›¸ä¼¼åº¦è¿‡ä½ ({best_similarity:.3f})ï¼Œä¸ä½¿ç”¨è§’è‰²ä¿¡æ¯")
            return None

        best_role = self.roles_data[best_role_idx]
        print(f"   ğŸ¯ è¯­ä¹‰åŒ¹é…æˆåŠŸï¼Œç›¸ä¼¼åº¦: {best_similarity:.3f}")

        # æ·»åŠ åŒ¹é…ä¿¡æ¯åˆ°è§’è‰²æ•°æ®
        best_role_copy = best_role.copy()
        best_role_copy['semantic_similarity'] = float(best_similarity)
        best_role_copy['matching_method'] = 'semantic'

        return best_role_copy

    def _precompute_role_embeddings(self, batch_size: int = 50):
        """é¢„è®¡ç®—æ‰€æœ‰è§’è‰²çš„è¯­ä¹‰åµŒå…¥å‘é‡"""
        print("ğŸ”„ é¢„è®¡ç®—è§’è‰²è¯­ä¹‰åµŒå…¥å‘é‡...")

        try:
            # å°è¯•ä»æŒä¹…åŒ–å­˜å‚¨åŠ è½½
            if self._load_role_embeddings():
                return

            print("   æœªæ‰¾åˆ°å¯ç”¨çš„ç¼“å­˜ï¼Œå¼€å§‹è®¡ç®—åµŒå…¥å‘é‡...")

            # æ‰¹é‡å¤„ç†ä»¥æé«˜æ•ˆç‡
            role_texts = []
            for role in self.roles_data:
                role_text = self._build_role_text_representation(role)
                role_texts.append(role_text)

            # åˆ†æ‰¹è®¡ç®—åµŒå…¥å‘é‡
            embeddings = []
            for i in range(0, len(role_texts), batch_size):
                batch_texts = role_texts[i:i + batch_size]
                batch_embeddings = self._get_embeddings_batch(batch_texts)
                embeddings.extend(batch_embeddings)

                # æ˜¾ç¤ºè¿›åº¦
                processed = min(i + batch_size, len(role_texts))
                print(f"   å¤„ç†è¿›åº¦: {processed}/{len(role_texts)}")

            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            self.role_embeddings = np.array(embeddings)

            # ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
            self._save_role_embeddings()

            print(f"âœ… å®Œæˆ {len(self.role_embeddings)} ä¸ªè§’è‰²çš„åµŒå…¥å‘é‡è®¡ç®—")

        except Exception as e:
            print(f"âŒ é¢„è®¡ç®—è§’è‰²åµŒå…¥å¤±è´¥: {e}")
            self.use_semantic_matching = False
            self.role_embeddings = []

    def _get_embeddings_batch(self, texts: List[str]) -> List[np.ndarray]:
        """æ‰¹é‡è·å–åµŒå…¥å‘é‡"""
        try:
            response = self.openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=texts
            )
            return [np.array(item.embedding) for item in response.data]
        except Exception as e:
            print(f"æ‰¹é‡è·å–åµŒå…¥å‘é‡å¤±è´¥: {e}")
            # é€ä¸ªå¤„ç†ä½œä¸ºfallback
            return [self._get_embedding(text) for text in texts]

    def _load_role_embeddings(self) -> bool:
        """
        ä»æŒä¹…åŒ–å­˜å‚¨åŠ è½½è§’è‰²åµŒå…¥å‘é‡

        Returns:
            æ˜¯å¦æˆåŠŸåŠ è½½
        """
        try:
            # ç®€å•æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not self.role_embeddings_file.exists():
                return False

            # ç›´æ¥åŠ è½½åµŒå…¥å‘é‡
            self.role_embeddings = np.load(self.role_embeddings_file)

            print(f"âœ… ä»ç¼“å­˜åŠ è½½äº† {len(self.role_embeddings)} ä¸ªè§’è‰²çš„åµŒå…¥å‘é‡")
            return True

        except Exception as e:
            print(f"   âš ï¸  ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
            return False

    def _save_role_embeddings(self):
        """ä¿å­˜è§’è‰²åµŒå…¥å‘é‡åˆ°æŒä¹…åŒ–å­˜å‚¨"""
        try:
            # ç®€å•ä¿å­˜åµŒå…¥å‘é‡
            np.save(self.role_embeddings_file, self.role_embeddings)
            print(f"ğŸ’¾ åµŒå…¥å‘é‡å·²ä¿å­˜: {self.role_embeddings_file}")

        except Exception as e:
            print(f"âš ï¸  ä¿å­˜å¤±è´¥: {e}")

    def clear_cache(self):
        """æ¸…ç†è§’è‰²åµŒå…¥ç¼“å­˜"""
        try:
            if self.role_embeddings_file.exists():
                self.role_embeddings_file.unlink()
                print(f"âœ… åˆ é™¤ç¼“å­˜æ–‡ä»¶: {self.role_embeddings_file}")

            # æ¸…ç†å†…å­˜æ•°æ®
            self.role_embeddings = []
            self.template_cache = {}
            print("ğŸ”„ ç¼“å­˜å·²æ¸…ç†")

        except Exception as e:
            print(f"âš ï¸  æ¸…ç†å¤±è´¥: {e}")

    def rebuild_cache(self):
        """é‡æ–°æ„å»ºè§’è‰²åµŒå…¥ç¼“å­˜"""
        print("ğŸ”„ å¼€å§‹é‡æ–°æ„å»ºè§’è‰²åµŒå…¥ç¼“å­˜...")

        # æ¸…ç†ç°æœ‰ç¼“å­˜
        self.clear_cache()

        # å¦‚æœå¯ç”¨è¯­ä¹‰åŒ¹é…ï¼Œé‡æ–°è®¡ç®—åµŒå…¥
        if self.use_semantic_matching and self.openai_client:
            self._precompute_role_embeddings()

    def _build_role_text_representation(self, role_data: Dict[str, Any]) -> str:
        """æ„å»ºè§’è‰²çš„æ–‡æœ¬è¡¨ç¤ºï¼Œç”¨äºè®¡ç®—åµŒå…¥å‘é‡"""
        components = []

        # æ·»åŠ è§’è‰²æè¿°
        player_desc = role_data.get('player_description', '')
        if player_desc:
            components.append(f"ç©å®¶ç‰¹å¾: {player_desc}")

        # æ·»åŠ æ¥æºå†…å®¹
        source_content = role_data.get('source_content', '')
        if source_content:
            components.append(f"åŸå§‹é—®é¢˜: {source_content}")

        # æ·»åŠ è¯é¢˜ä¿¡æ¯
        source_topic = role_data.get('source_topic', '')
        if source_topic:
            components.append(f"ç›¸å…³è¯é¢˜: {source_topic}")

        return " ".join(components)

    def _build_template_text_representation(self, template_data: Dict[str, Any]) -> str:
        """æ„å»ºé—®é¢˜æ¨¡æ¿çš„æ–‡æœ¬è¡¨ç¤º"""
        components = []

        # æ·»åŠ æ¨¡æ¿å†…å®¹
        template = template_data.get('template', '')
        if template:
            components.append(f"é—®é¢˜æ¨¡æ¿: {template}")

        # æ·»åŠ é—®é¢˜ç±»å‹
        question_topic = template_data.get('question_topic', '')
        if question_topic:
            components.append(f"é—®é¢˜ç±»å‹: {question_topic}")

        # æ·»åŠ æè¿°
        description = template_data.get('description', '')
        if description:
            components.append(f"æè¿°: {description}")

        # æ·»åŠ è¯é¢˜ä¿¡æ¯
        topic = template_data.get('topic', '')
        if topic:
            components.append(f"è¯é¢˜: {topic}")

        return " ".join(components)

    def _get_embedding(self, text: str) -> np.ndarray:
        """è·å–æ–‡æœ¬çš„åµŒå…¥å‘é‡"""
        try:
            response = self.openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=text
            )
            return np.array(response.data[0].embedding)
        except Exception as e:
            print(f"è·å–åµŒå…¥å‘é‡å¤±è´¥: {e}")
            # è¿”å›éšæœºå‘é‡ä½œä¸ºfallback
            return np.random.rand(1536)  # text-embedding-3-smallçš„ç»´åº¦

    def get_role_context(self, role_data: Dict[str, Any]) -> str:
        """
        è·å–è§’è‰²ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç”¨äºç”Ÿæˆæ—¶çš„è§’è‰²æ‰®æ¼”

        Args:
            role_data: è§’è‰²æ•°æ®

        Returns:
            è§’è‰²ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        if not role_data:
            return ""

        player_description = role_data.get('player_description', '')

        context = f"""
            ç©å®¶è§’è‰²èƒŒæ™¯ï¼š
            {player_description}

            è¯·ä»¥è¿™ä¸ªç©å®¶çš„èº«ä»½å’Œè¯­è¨€é£æ ¼æ¥æé—®å’Œæ€è€ƒé—®é¢˜ã€‚

            **é‡è¦è¦æ±‚**ï¼šä½œä¸ºè¿™ä¸ªè§’è‰²æé—®æ—¶ï¼Œå¿…é¡»æä¾›å…·ä½“çš„ç»†èŠ‚ä¿¡æ¯ï¼š
            - å¦‚æœæ¶‰åŠç¡¬ä»¶é—®é¢˜ï¼Œè¦æ˜ç¡®è¯´æ˜å…·ä½“çš„ç¡¬ä»¶å‹å·
            - å¦‚æœæ¶‰åŠæ¸¸æˆå†…å®¹ï¼Œè¦ä½¿ç”¨å‡†ç¡®çš„æ¸¸æˆæœ¯è¯­å’Œåç§°
            - å¦‚æœæ¶‰åŠæ•°å€¼ï¼Œè¦ç»™å‡ºå…·ä½“çš„æ•°å€¼æˆ–èŒƒå›´
            - **ç‰ˆæœ¬ç›¸å…³æ³¨æ„äº‹é¡¹**ï¼šä¸è¦åœ¨é—®é¢˜ä¸­ç›´æ¥æåŠç‰ˆæœ¬å·ï¼Œè€Œåº”è¯¥ç”¨è‡ªç„¶çš„è¡¨è¿°ï¼ˆå¦‚"æœ€è¿‘"ã€"ç°åœ¨"ç­‰ï¼‰ï¼Œç‰ˆæœ¬ä¿¡æ¯é€šè¿‡æé—®æ—¶é—´æ¥ä½“ç°
            - é¿å…ä½¿ç”¨æ¨¡ç³Šçš„è¡¨è¿°ï¼Œç¡®ä¿é—®é¢˜æœ‰è¶³å¤Ÿçš„ä¿¡æ¯æ¥ç»™å‡ºå‡†ç¡®å›ç­”
        """
        return context.strip()

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–è§’è‰²æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_roles': len(self.roles_data),
            'total_topics': len(self.topic_to_roles),
            'semantic_matching_enabled': self.use_semantic_matching,
            'embeddings_computed': len(self.role_embeddings) > 0,
            'cache_exists': self.role_embeddings_file.exists()
        }

    def get_top_similar_roles(self, template_data: Dict[str, Any], top_k: int = 5) -> List[Dict[str, Any]]:
        """
        è·å–ä¸æ¨¡æ¿æœ€ç›¸ä¼¼çš„å‰Kä¸ªè§’è‰²ï¼ˆç”¨äºè°ƒè¯•å’Œåˆ†æï¼‰

        Args:
            template_data: é—®é¢˜æ¨¡æ¿æ•°æ®
            top_k: è¿”å›çš„è§’è‰²æ•°é‡

        Returns:
            ç›¸ä¼¼åº¦æœ€é«˜çš„è§’è‰²åˆ—è¡¨
        """
        if not self.use_semantic_matching or len(self.role_embeddings) == 0:
            # å¦‚æœè¯­ä¹‰åŒ¹é…ä¸å¯ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
            return []

        try:
            # æ„å»ºæ¨¡æ¿çš„æ–‡æœ¬è¡¨ç¤ºå¹¶è·å–åµŒå…¥å‘é‡
            template_text = self._build_template_text_representation(template_data)
            template_embedding = self._get_embedding(template_text)

            # è®¡ç®—ç›¸ä¼¼åº¦
            similarities = cosine_similarity(
                template_embedding.reshape(1, -1),
                self.role_embeddings
            ).flatten()

            # è·å–å‰Kä¸ªæœ€ç›¸ä¼¼çš„è§’è‰²
            top_indices = np.argsort(similarities)[::-1][:top_k]

            result = []
            for idx in top_indices:
                role = self.roles_data[idx].copy()
                role['semantic_similarity'] = float(similarities[idx])
                role['rank'] = len(result) + 1
                result.append(role)

            return result

        except Exception as e:
            print(f"è·å–ç›¸ä¼¼è§’è‰²å¤±è´¥: {e}")
            return []
