"""
QAé—®ç­”å¯¹ä¼˜åŒ–å™¨ç»„ä»¶ - ç”¨äºç”Ÿæˆæµç¨‹ä¸­çš„QAä¼˜åŒ–
ä»question_refine.pyä¸­æå–æ ¸å¿ƒåŠŸèƒ½ï¼Œé›†æˆåˆ°ç”Ÿæˆæµç¨‹ä¸­
"""

import json
import time
from typing import Dict, Any, Tuple, Optional
from openai import OpenAI
from prompt import qa_refiner_system_prompt, qa_refiner_user_prompt


class QARefiner:
    """QAé—®ç­”å¯¹ä¼˜åŒ–å™¨ç»„ä»¶"""

    def __init__(self,
                 api_key: str,
                 base_url: str,
                 model_name: str,
                 base_path: str):
        """
        åˆå§‹åŒ–QAä¼˜åŒ–å™¨

        Args:
            api_key: OpenAI APIå¯†é’¥
            base_url: APIåŸºç¡€URL
            model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°
            base_path: åŸºç¡€è·¯å¾„
        """
        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.model_name = model_name
        self.base_path = base_path

    def get_refine_prompt(self) -> Tuple[str, str]:
        """
        è·å–ä¼˜åŒ–é—®ç­”å¯¹çš„ç³»ç»Ÿå’Œç”¨æˆ·promptï¼ˆä»prompt.pyå¯¼å…¥ï¼‰

        Returns:
            Tuple[str, str]: (ç³»ç»Ÿprompt, ç”¨æˆ·promptæ¨¡æ¿)
        """
        return qa_refiner_system_prompt, qa_refiner_user_prompt

    def extract_retrieved_docs_content(self, qa_item: Dict[str, Any]) -> str:
        """
        æå–retrieved_docsä¸­çš„å†…å®¹

        Args:
            qa_item: QAæ•°æ®é¡¹

        Returns:
            str: æ ¼å¼åŒ–çš„æ–‡æ¡£å†…å®¹
        """
        retrieved_docs = qa_item.get('retrieved_docs', [])
        if not retrieved_docs:
            return "No reference documents available."

        docs_content = []
        for i, doc in enumerate(retrieved_docs, 1):
            content = doc.get('content', '').strip()
            if content:
                docs_content.append(f"Document {i}:\n{content}")

        return "\n\n".join(docs_content) if docs_content else "No reference documents available."

    def refine_qa_pair(self, qa_item: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        ä¼˜åŒ–å•ä¸ªQAé—®ç­”å¯¹

        Args:
            qa_item: åŸå§‹QAæ•°æ®é¡¹

        Returns:
            Optional[Dict[str, Any]]: ä¼˜åŒ–åçš„QAæ•°æ®é¡¹ï¼Œå¦‚æœä¼˜åŒ–å¤±è´¥è¿”å›None
        """
        try:
            # æå–åŸå§‹é—®ç­”å†…å®¹è¿›è¡Œé•¿åº¦æ£€æŸ¥
            original_question = qa_item.get('question', '')
            original_answer = qa_item.get('answer', '')

            # é•¿åº¦æ£€æŸ¥
            if len(original_question) > 250:
                print(f"    âš ï¸  é—®é¢˜è¿‡é•¿({len(original_question)}å­—ç¬¦ > 250)ï¼Œè·³è¿‡ä¼˜åŒ–")
                return None

            if len(original_answer) > 500:
                print(f"    âš ï¸  ç­”æ¡ˆè¿‡é•¿({len(original_answer)}å­—ç¬¦ > 500)ï¼Œè·³è¿‡ä¼˜åŒ–")
                return None

            system_prompt, user_prompt_template = self.get_refine_prompt()

            game_name = qa_item.get('game_name', 'Unknown')
            question_topic = qa_item.get('question_topic', 'Unknown')
            task_type = qa_item.get('task_type', 'Unknown')

            # æå–retrieved_docså†…å®¹
            retrieved_docs_content = self.extract_retrieved_docs_content(qa_item)

            # æ„é€ ç”¨æˆ·prompt
            user_prompt = user_prompt_template.format(
                question=original_question,
                answer=original_answer,
                retrieved_docs_content=retrieved_docs_content,
                game_name=game_name,
                question_type=question_topic,
                task_type=task_type
            )

            print("    ğŸ”„ æ­£åœ¨ä¼˜åŒ–é—®ç­”å¯¹...")

            # è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œä¼˜åŒ–
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=8000,
                temperature=0.3,  # è¾ƒä½çš„temperatureç¡®ä¿ç¨³å®šæ€§
                response_format={"type": "json_object"}
            )

            response_text = response.choices[0].message.content.strip()

            # è§£æå“åº”
            try:
                # æ¸…ç†å“åº”æ–‡æœ¬ï¼ˆç§»é™¤å¯èƒ½çš„markdownæ ‡è®°ï¼‰
                cleaned_text = response_text
                if cleaned_text.startswith("```json"):
                    cleaned_text = cleaned_text[7:]
                if cleaned_text.endswith("```"):
                    cleaned_text = cleaned_text[:-3]
                cleaned_text = cleaned_text.strip()

                optimization_result = json.loads(cleaned_text)

                # åˆ›å»ºä¼˜åŒ–åçš„QAé¡¹ï¼Œä¿ç•™åŸå§‹æ•°æ®çš„å…¶ä»–å­—æ®µ
                refined_qa_item = qa_item.copy()
                refined_qa_item.update({
                    'question': optimization_result.get('optimized_question', original_question),
                    'answer': optimization_result.get('optimized_answer', original_answer),
                    'optimization_notes': optimization_result.get('optimization_notes', ''),
                    'original_question': original_question,  # ä¿å­˜åŸå§‹é—®é¢˜
                    'original_answer': original_answer,      # ä¿å­˜åŸå§‹ç­”æ¡ˆ
                    'optimized': True,                       # æ ‡è®°å·²ä¼˜åŒ–
                    'optimization_timestamp': time.time()    # ä¼˜åŒ–æ—¶é—´æˆ³
                })

                print("    âœ… ä¼˜åŒ–å®Œæˆ")
                return refined_qa_item

            except json.JSONDecodeError as e:
                print(f"    âŒ JSONè§£æå¤±è´¥: {e}")
                return None

        except Exception as e:
            print(f"    âŒ ä¼˜åŒ–å¤±è´¥: {e}")
            return None
