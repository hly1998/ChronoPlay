# QAæ•°æ®è´¨é‡è¿‡æ»¤ç»„ä»¶
import sys
import json
from pathlib import Path
from typing import List, Dict, Any, Optional

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥ä¾¿å¯¼å…¥utils
sys.path.append(str(Path(__file__).parent.parent))

# è¿™äº›æ¨¡å—å¯¼å…¥å¿…é¡»åœ¨pathè®¾ç½®ä¹‹åï¼Œå› ä¸ºå®ƒä»¬ä¾èµ–äºé¡¹ç›®å†…éƒ¨æ¨¡å—
from openai import OpenAI  # noqa: E402
from utils.utils import (  # noqa: E402
    clean_response_text,
    get_question_type_description
)
from prompt import data_filter_system, data_filter_user  # noqa: E402
# ä»æ–°çš„question_type.jsonæ–‡ä»¶åŠ è½½ä»»åŠ¡æè¿°


class QAFilter:
    """QAæ•°æ®è´¨é‡è¿‡æ»¤å™¨ç»„ä»¶"""

    def __init__(self,
                 api_key: str,
                 base_url: str,
                 model_name: str = "gpt-4o",
                 question_topics_map: Optional[Dict[str, Any]] = None,
                 question_types_map: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–QAè¿‡æ»¤å™¨

        Args:
            api_key: OpenAI APIå¯†é’¥
            base_url: APIåŸºç¡€URL
            model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°
            question_topics_map: é—®é¢˜ä¸»é¢˜æ˜ å°„
            question_types_map: é—®é¢˜ç±»å‹æ˜ å°„
        """
        self.model_name = model_name

        # åŠ è½½é—®é¢˜ä¸»é¢˜æ˜ å°„å’Œé—®é¢˜ç±»å‹æ˜ å°„
        base_path = Path(__file__).parent.parent.parent

        if question_topics_map:
            self.question_topics_map = question_topics_map
        else:
            question_topics_file = base_path / "global_vars" / "question_topics.json"
            with open(question_topics_file, 'r', encoding='utf-8') as f:
                self.question_topics_map = json.load(f)

        if question_types_map:
            self.question_types_map = question_types_map
        else:
            question_types_file = base_path / "global_vars" / "question_type.json"
            with open(question_types_file, 'r', encoding='utf-8') as f:
                self.question_types_map = json.load(f)

        # task_descriptionå°±æ˜¯question_types_map
        self.task_description = self.question_types_map

        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        self.client = OpenAI(api_key=api_key, base_url=base_url)

        print("ğŸ”§ QAè¿‡æ»¤å™¨ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
        print(f"   æ¨¡å‹: {self.model_name}")
        print("   ä½¿ç”¨æ£€ç´¢ç‰‡æ®µè¿›è¡Œè´¨é‡è¯„ä¼°")

    def get_related_documents(self, qa_item: Dict[str, Any]) -> str:
        """è·å–ä¸QAç›¸å…³çš„æ£€ç´¢æ–‡æ¡£ç‰‡æ®µ"""
        retrieved_docs = qa_item.get('retrieved_docs', [])
        doc_content = ""

        for i, doc in enumerate(retrieved_docs, 1):
            # ç›´æ¥ä½¿ç”¨æ£€ç´¢ç‰‡æ®µå†…å®¹
            content = doc.get('content', '')
            doc_content += f"æ–‡æ¡£{i}:\n{content}\n\n"

        return doc_content.strip()

    def evaluate_qa_quality(self, qa_item: Dict[str, Any]) -> int:
        """ä½¿ç”¨å¤§æ¨¡å‹è¯„ä¼°å•æ¡QAæ•°æ®çš„è´¨é‡ï¼Œè¿”å›è´¨é‡è¯„åˆ†"""
        try:
            # è·å–ç›¸å…³æ–‡æ¡£
            doc_content = self.get_related_documents(qa_item)

            # è·å–é—®é¢˜ä¸»é¢˜æè¿°
            question_topic = qa_item.get('question_topic', '')
            question_topic_desc = get_question_type_description(question_topic, self.question_topics_map)

            # è·å–ä»»åŠ¡æè¿°
            task_type = qa_item.get('task_type', '')
            task_desc = self.task_description.get(task_type, '')

            # æ„å»ºè¯„ä¼°ç”¨çš„æ•°æ®æ ¼å¼
            gen_data = [{
                "question": qa_item.get('question', ''),
                "answer": qa_item.get('answer', ''),
                "time": qa_item.get('time', ''),
                "relevant_passage": qa_item.get('references', [])
            }]

            # å¦‚æœansweræ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
            if isinstance(gen_data[0]["answer"], str):
                gen_data[0]["answer"] = [gen_data[0]["answer"]]

            # æ„å»ºç”¨æˆ·æç¤º
            user_prompt = data_filter_user.format(
                doc_str=doc_content,
                topic_name=question_topic_desc,
                task_name=task_type,
                task_require=task_desc,
                gen_datas=json.dumps(gen_data, ensure_ascii=False, indent=2)
            )

            print("  ğŸ” è°ƒç”¨å¤§æ¨¡å‹è¿›è¡ŒQAè´¨é‡è¯„ä¼°...")
            print(f"    é—®é¢˜ä¸»é¢˜: {question_topic} -> {question_topic_desc}")
            print(f"    ä»»åŠ¡ç±»å‹: {task_type}")
            print(f"    æ–‡æ¡£æ•°é‡: {len(qa_item.get('retrieved_docs', []))}")

            # è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œè¯„ä¼°
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": data_filter_system},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=1000,  # å‡å°‘tokenæ•°é‡ï¼Œå› ä¸ºä¸éœ€è¦ä¿®æ­£ç»“æœ
                temperature=0.1
            )

            response_text = response.choices[0].message.content.strip()
            print(f"  ğŸ“ åŸå§‹å“åº”é•¿åº¦: {len(response_text)}")

            cleaned_text = clean_response_text(response_text)
            print(f"  ğŸ§¹ æ¸…ç†åå“åº”é•¿åº¦: {len(cleaned_text)}")

            if not cleaned_text:
                print("  âš ï¸  æ¸…ç†åçš„å“åº”ä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹å“åº”")
                cleaned_text = response_text

            # è§£æè¯„ä¼°ç»“æœï¼Œåªå…³æ³¨evaluationå­—æ®µ
            print(f"  ğŸ” å‡†å¤‡è§£æçš„æ–‡æœ¬: {cleaned_text[:200]}...")
            eval_result = json.loads(cleaned_text)
            print(f"  ğŸ“Š è§£æç»“æœç±»å‹: {type(eval_result)}")

            # ç¡®ä¿eval_resultæ˜¯å­—å…¸ç±»å‹
            if isinstance(eval_result, dict):
                quality_score = eval_result.get('evaluation', 0)
                print(f"  âœ… JSONè§£ææˆåŠŸï¼Œè´¨é‡è¯„åˆ†: {quality_score}")
            elif isinstance(eval_result, str):
                print(f"  âš ï¸  è§£æç»“æœæ˜¯å­—ç¬¦ä¸²: {eval_result[:100]}...")
                quality_score = 0
            else:
                print(f"  âš ï¸  è§£æç»“æœç±»å‹æœªçŸ¥: {type(eval_result)} - {eval_result}")
                quality_score = 0

            return quality_score

        except json.JSONDecodeError as e:
            print(f"  âŒ JSONè§£æå¤±è´¥: {e}")
            print(f"  ğŸ“ è¦è§£æçš„æ–‡æœ¬: {cleaned_text[:500] if 'cleaned_text' in locals() else 'æ— '}")
            return 0
        except Exception as e:
            print(f"  âŒ è¯„ä¼°å¤±è´¥: {e}")
            return 0

    def filter_qa_pair(self, qa_item: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        è¿‡æ»¤å•ä¸ªQAå¯¹ï¼Œåªä¿ç•™é«˜è´¨é‡æ•°æ®

        Returns:
            å¦‚æœQAå¯¹è´¨é‡ä¸ºé«˜è´¨é‡(è¯„åˆ†=2)ï¼Œè¿”å›åŸå§‹QAå¯¹ï¼›å¦åˆ™è¿”å›None
        """
        # è¯„ä¼°æ•°æ®è´¨é‡
        quality_score = self.evaluate_qa_quality(qa_item)

        print(f"    è´¨é‡è¯„åˆ†: {quality_score}")

        # é™ä½è´¨é‡é˜ˆå€¼ï¼šä¿ç•™è¯„åˆ†ä¸º1å’Œ2çš„æ•°æ®ï¼Œåªä¸¢å¼ƒè¯„åˆ†ä¸º0çš„æ•°æ®
        if quality_score >= 1:
            print("    âœ… è´¨é‡åˆæ ¼æ•°æ®ï¼Œä¿ç•™")
            return qa_item
        else:
            # åªä¸¢å¼ƒæœ€ä½è´¨é‡æ•°æ®(è¯„åˆ†=0)
            print(f"    âŒ ä½è´¨é‡æ•°æ®(è¯„åˆ†={quality_score})ï¼Œä¸¢å¼ƒ")
            return None

    def filter_qa_batch(self, qa_pairs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡è¿‡æ»¤QAå¯¹ï¼Œä¿ç•™è´¨é‡åˆæ ¼çš„æ•°æ®

        Args:
            qa_pairs: QAå¯¹åˆ—è¡¨

        Returns:
            è¿‡æ»¤åçš„QAå¯¹åˆ—è¡¨ï¼ˆåŒ…å«è´¨é‡è¯„åˆ†>=1çš„æ•°æ®ï¼‰
        """
        filtered_qa_pairs = []
        stats = {'total': 0, 'qualified': 0, 'discarded': 0}

        for qa_item in qa_pairs:
            stats['total'] += 1
            print(f"  è¿‡æ»¤ç¬¬ {stats['total']}/{len(qa_pairs)} ä¸ªQAå¯¹...")
            print(f"    é—®é¢˜: {qa_item.get('question', '')[:50]}...")

            filtered_qa = self.filter_qa_pair(qa_item)

            if filtered_qa:
                filtered_qa_pairs.append(filtered_qa)
                stats['qualified'] += 1
            else:
                stats['discarded'] += 1

        print(f"  ğŸ“Š æ‰¹é‡è¿‡æ»¤ç»Ÿè®¡: æ€»æ•°({stats['total']}) åˆæ ¼({stats['qualified']}) ä¸¢å¼ƒ({stats['discarded']})")

        return filtered_qa_pairs
